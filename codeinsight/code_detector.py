import libcst as cst
from typing import Dict, List, Set, Tuple, Optional
from dataclasses import dataclass, field
from collections import defaultdict
import difflib


@dataclass
class CodeBlock:
    """ä»£ç å—ä¿¡æ¯"""
    start_line: int
    end_line: int
    content: str
    hash_value: str

    @property
    def line_count(self) -> int:
        return self.end_line - self.start_line + 1


@dataclass
class DuplicatePair:
    """é‡å¤ä»£ç å¯¹"""
    block1: CodeBlock
    block2: CodeBlock
    similarity: float
    type: str  # 'exact' or 'similar'


@dataclass
class DuplicateReport:
    """é‡å¤æ£€æµ‹æŠ¥å‘Š"""
    total_blocks: int
    exact_duplicates: int
    similar_duplicates: int
    duplicate_pairs: List[DuplicatePair]
    duplicate_lines: int
    total_lines: int
    duplicate_percentage: float


class CodeDuplicateDetector:
    """ä»£ç é‡å¤æ£€æµ‹å™¨"""

    def __init__(
        self,
        min_block_size: int = 5,
        similarity_threshold: float = 0.85,
        ignore_comments: bool = True,
        ignore_whitespace: bool = True
    ):
        self.min_block_size = min_block_size
        self.similarity_threshold = similarity_threshold
        self.ignore_comments = ignore_comments
        self.ignore_whitespace = ignore_whitespace

    def detect(self, source: str) -> DuplicateReport:
        """æ£€æµ‹ä»£ç é‡å¤"""
        lines = source.split('\n')
        total_lines = len(lines)

        if self.ignore_comments:
            lines = self._remove_comments(lines)

        if self.ignore_whitespace:
            lines = [line.strip() for line in lines]

        blocks = self._extract_blocks(lines)
        exact_duplicates, similar_duplicates = self._find_duplicates(blocks)

        duplicate_lines = self._calculate_duplicate_lines(exact_duplicates, similar_duplicates)

        return DuplicateReport(
            total_blocks=len(blocks),
            exact_duplicates=len(exact_duplicates),
            similar_duplicates=len(similar_duplicates),
            duplicate_pairs=exact_duplicates + similar_duplicates,
            duplicate_lines=duplicate_lines,
            total_lines=total_lines,
            duplicate_percentage=(duplicate_lines / total_lines * 100) if total_lines > 0 else 0
        )

    def _remove_comments(self, lines: List[str]) -> List[str]:
        """ç§»é™¤æ³¨é‡Šè¡Œ"""
        result = []
        in_multiline_comment = False
        for line in lines:
            stripped = line.strip()
            if '"""' in stripped or "'''" in stripped:
                in_multiline_comment = not in_multiline_comment
                continue
            if in_multiline_comment:
                continue
            if stripped.startswith('#'):
                continue
            result.append(line)
        return result

    def _extract_blocks(self, lines: List[str]) -> List[CodeBlock]:
        """æå–ä»£ç å—"""
        blocks = []
        n = len(lines)

        for start in range(n - self.min_block_size + 1):
            for end in range(start + self.min_block_size, min(start + 30, n + 1)):
                block_lines = lines[start:end]
                content = '\n'.join(block_lines)
                hash_value = self._compute_hash(content)
                blocks.append(CodeBlock(
                    start_line=start + 1,
                    end_line=end,
                    content=content,
                    hash_value=hash_value
                ))

        return blocks

    def _compute_hash(self, content: str) -> str:
        """è®¡ç®—å†…å®¹çš„å“ˆå¸Œå€¼"""
        import hashlib
        normalized = '\n'.join(line.strip() for line in content.strip().split('\n') if line.strip())
        return hashlib.md5(normalized.encode()).hexdigest()

    def _find_duplicates(self, blocks: List[CodeBlock]) -> Tuple[List[DuplicatePair], List[DuplicatePair]]:
        """æŸ¥æ‰¾é‡å¤ä»£ç å—"""
        exact_duplicates = []
        similar_duplicates = []

        hash_to_blocks = defaultdict(list)
        for block in blocks:
            hash_to_blocks[block.hash_value].append(block)

        for hash_value, matching_blocks in hash_to_blocks.items():
            if len(matching_blocks) > 1:
                for i in range(len(matching_blocks)):
                    for j in range(i + 1, len(matching_blocks)):
                        exact_duplicates.append(DuplicatePair(
                            block1=matching_blocks[i],
                            block2=matching_blocks[j],
                            similarity=1.0,
                            type='exact'
                        ))

        for i in range(len(blocks)):
            for j in range(i + 1, len(blocks)):
                if blocks[i].hash_value != blocks[j].hash_value:
                    similarity = self._calculate_similarity(blocks[i].content, blocks[j].content)
                    if similarity >= self.similarity_threshold:
                        similar_duplicates.append(DuplicatePair(
                            block1=blocks[i],
                            block2=blocks[j],
                            similarity=similarity,
                            type='similar'
                        ))

        similar_duplicates = self._deduplicate_similar(similar_duplicates)

        return exact_duplicates, similar_duplicates

    def _calculate_similarity(self, content1: str, content2: str) -> float:
        """è®¡ç®—ä¸¤ä¸ªä»£ç å—çš„ç›¸ä¼¼åº¦"""
        lines1 = content1.split('\n')
        lines2 = content2.split('\n')

        matcher = difflib.SequenceMatcher(None, lines1, lines2)
        return matcher.ratio()

    def _deduplicate_similar(self, similar_duplicates: List[DuplicatePair]) -> List[DuplicatePair]:
        """å»é‡ç›¸ä¼¼çš„é‡å¤å¯¹"""
        seen = set()
        result = []

        for pair in similar_duplicates:
            key = (pair.block1.start_line, pair.block1.end_line,
                   pair.block2.start_line, pair.block2.end_line)
            if key not in seen:
                seen.add(key)
                result.append(pair)

        return result

    def _calculate_duplicate_lines(
        self,
        exact_duplicates: List[DuplicatePair],
        similar_duplicates: List[DuplicatePair]
    ) -> int:
        """è®¡ç®—é‡å¤è¡Œæ•°"""
        covered_lines = set()

        for pair in exact_duplicates + similar_duplicates:
            for line in range(pair.block1.start_line, pair.block1.end_line + 1):
                covered_lines.add(line)

        return len(covered_lines)


class ASTBasedDuplicateDetector:
    """åŸºäºASTçš„ä»£ç é‡å¤æ£€æµ‹å™¨"""

    def __init__(self, min_function_size: int = 5):
        self.min_function_size = min_function_size

    def detect(self, tree: cst.Module, source: str) -> DuplicateReport:
        """åŸºäºASTæ£€æµ‹é‡å¤å‡½æ•°"""
        functions = self._extract_functions(tree, source)
        exact_duplicates, similar_duplicates = self._find_function_duplicates(functions)

        total_lines = len(source.split('\n'))
        duplicate_lines = self._calculate_duplicate_lines(exact_duplicates, similar_duplicates)

        return DuplicateReport(
            total_blocks=len(functions),
            exact_duplicates=len(exact_duplicates),
            similar_duplicates=len(similar_duplicates),
            duplicate_pairs=exact_duplicates + similar_duplicates,
            duplicate_lines=duplicate_lines,
            total_lines=total_lines,
            duplicate_percentage=(duplicate_lines / total_lines * 100) if total_lines > 0 else 0
        )

    def _extract_functions(self, tree: cst.Module, source: str) -> List[CodeBlock]:
        """æå–æ‰€æœ‰å‡½æ•°"""
        functions = []
        lines = source.split('\n')

        wrapper = cst.metadata.MetadataWrapper(tree)
        positions = wrapper.resolve(cst.metadata.PositionProvider)

        class FunctionExtractor(cst.CSTVisitor):
            def __init__(self, outer):
                self.outer = outer
                self.functions = []

            def visit_FunctionDef(self, node: cst.FunctionDef) -> bool:
                pos = positions[node]
                start_line = pos.start.line
                end_line = pos.end.line

                if end_line - start_line + 1 >= self.outer.min_function_size:
                    content = '\n'.join(lines[start_line - 1:end_line])
                    hash_value = self.outer._compute_hash(content)
                    self.functions.append(CodeBlock(
                        start_line=start_line,
                        end_line=end_line,
                        content=content,
                        hash_value=hash_value
                    ))
                return True

        extractor = FunctionExtractor(self)
        wrapper.visit(extractor)
        return extractor.functions

    def _compute_hash(self, content: str) -> str:
        """è®¡ç®—å†…å®¹çš„å“ˆå¸Œå€¼"""
        import hashlib
        import re
        
        lines = content.split('\n')
        result = []
        
        for line in lines:
            stripped = line.strip()
            if stripped:
                result.append(stripped)
        
        normalized = '\n'.join(result)
        return hashlib.md5(normalized.encode()).hexdigest()

    def _find_function_duplicates(
        self,
        functions: List[CodeBlock]
    ) -> Tuple[List[DuplicatePair], List[DuplicatePair]]:
        """æŸ¥æ‰¾é‡å¤å‡½æ•°"""
        exact_duplicates = []
        similar_duplicates = []

        hash_to_functions = defaultdict(list)
        for func in functions:
            hash_to_functions[func.hash_value].append(func)

        for hash_value, matching_functions in hash_to_functions.items():
            if len(matching_functions) > 1:
                for i in range(len(matching_functions)):
                    for j in range(i + 1, len(matching_functions)):
                        exact_duplicates.append(DuplicatePair(
                            block1=matching_functions[i],
                            block2=matching_functions[j],
                            similarity=1.0,
                            type='exact'
                        ))

        for i in range(len(functions)):
            for j in range(i + 1, len(functions)):
                if functions[i].hash_value != functions[j].hash_value:
                    similarity = self._calculate_similarity(functions[i].content, functions[j].content)
                    if similarity >= 0.85:
                        similar_duplicates.append(DuplicatePair(
                            block1=functions[i],
                            block2=functions[j],
                            similarity=similarity,
                            type='similar'
                        ))

        return exact_duplicates, similar_duplicates

    def _calculate_similarity(self, content1: str, content2: str) -> float:
        """è®¡ç®—ä¸¤ä¸ªå‡½æ•°çš„ç›¸ä¼¼åº¦"""
        matcher = difflib.SequenceMatcher(None, content1, content2)
        return matcher.ratio()

    def _calculate_duplicate_lines(
        self,
        exact_duplicates: List[DuplicatePair],
        similar_duplicates: List[DuplicatePair]
    ) -> int:
        """è®¡ç®—é‡å¤è¡Œæ•°"""
        covered_lines = set()

        for pair in exact_duplicates + similar_duplicates:
            for line in range(pair.block1.start_line, pair.block1.end_line + 1):
                covered_lines.add(line)

        return len(covered_lines)


def format_duplicate_report(report: DuplicateReport, max_pairs: int = 10) -> str:
    """æ ¼å¼åŒ–é‡å¤æ£€æµ‹æŠ¥å‘Š"""
    lines = []
    lines.append("\nğŸ” ä»£ç é‡å¤æ£€æµ‹æŠ¥å‘Š")
    lines.append("-" * 40)

    lines.append(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    lines.append(f"  æ€»ä»£ç å—æ•°: {report.total_blocks}")
    lines.append(f"  å®Œå…¨é‡å¤: {report.exact_duplicates} å¯¹")
    lines.append(f"  ç›¸ä¼¼é‡å¤: {report.similar_duplicates} å¯¹")
    lines.append(f"  é‡å¤è¡Œæ•°: {report.duplicate_lines} / {report.total_lines}")
    lines.append(f"  é‡å¤æ¯”ä¾‹: {report.duplicate_percentage:.1f}%")

    if report.duplicate_pairs:
        lines.append(f"\nğŸ“‹ é‡å¤è¯¦æƒ… (æ˜¾ç¤ºå‰ {min(max_pairs, len(report.duplicate_pairs))} å¯¹):")

        for i, pair in enumerate(report.duplicate_pairs[:max_pairs], 1):
            emoji = "ğŸ”´" if pair.type == 'exact' else "ğŸŸ¡"
            lines.append(f"\n  {emoji} é‡å¤ #{i} ({pair.type}, ç›¸ä¼¼åº¦: {pair.similarity:.1%})")
            lines.append(f"     ä½ç½® 1: ç¬¬ {pair.block1.start_line}-{pair.block1.end_line} è¡Œ ({pair.block1.line_count} è¡Œ)")
            lines.append(f"     ä½ç½® 2: ç¬¬ {pair.block2.start_line}-{pair.block2.end_line} è¡Œ ({pair.block2.line_count} è¡Œ)")

            if pair.block1.line_count <= 10:
                lines.append(f"     ä»£ç ç‰‡æ®µ:")
                for line in pair.block1.content.split('\n')[:5]:
                    lines.append(f"       {line}")

    if report.duplicate_percentage > 10:
        lines.append(f"\nâš ï¸  è­¦å‘Š: ä»£ç é‡å¤ç‡è¾ƒé«˜ ({report.duplicate_percentage:.1f}%)ï¼Œå»ºè®®è¿›è¡Œé‡æ„")
    elif report.duplicate_percentage > 5:
        lines.append(f"\nğŸ’¡ æç¤º: ä»£ç é‡å¤ç‡é€‚ä¸­ ({report.duplicate_percentage:.1f}%)ï¼Œå¯è€ƒè™‘ä¼˜åŒ–")
    else:
        lines.append(f"\nâœ… ä»£ç é‡å¤ç‡è¾ƒä½ ({report.duplicate_percentage:.1f}%)ï¼Œä¿æŒè‰¯å¥½")

    return '\n'.join(lines)
